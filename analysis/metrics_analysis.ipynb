{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:32:54.637170Z",
     "start_time": "2024-04-22T16:32:54.572903Z"
    }
   },
   "source": [
    "import pandas\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "data = pandas.read_csv(\"data/221.csv\")\n",
    "data = data[data[\"fault.identified\"] == \"Superset (first MCS)\"]\n",
    "\n",
    "max_labels = 100"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "1e0f1d59519812aa",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-04-22T16:33:01.642246Z",
     "start_time": "2024-04-22T16:33:01.633532Z"
    }
   },
   "source": [
    "def parse_predictions(p):\n",
    "    if isinstance(p, float) and math.isnan(p):\n",
    "        p = \"[{}]\"\n",
    "    p = eval(p)[0]\n",
    "    return p\n",
    "\n",
    "def parse_truth(p):\n",
    "    if isinstance(p, float) and math.isnan(p):\n",
    "        p = \"{}\"\n",
    "    p = eval(p)\n",
    "    return p\n",
    "\n",
    "predictions = [parse_predictions(e) for e in data[\"fl.sorted\"]]\n",
    "truth = [parse_truth(e) for e in data[\"selfeval.lines\"]]"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T18:10:09.755610Z",
     "start_time": "2024-04-22T18:10:09.751345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import statistics\n",
    "\n",
    "n_extra_lines_in_fl = []\n",
    "\n",
    "for p, t in zip(predictions, truth):\n",
    "    n_extra_lines_in_fl.append(len(p - t))\n",
    "\n",
    "print(\"Mean:\", statistics.mean(n_extra_lines_in_fl))\n",
    "print(\"Median:\", statistics.median(n_extra_lines_in_fl))\n",
    "print(\"Number of cases with only one extra line:\", len([n for n in n_extra_lines_in_fl if n <= 1]) / len(n_extra_lines_in_fl))\n",
    "print(\"Max number of extra line:\", max(n_extra_lines_in_fl))"
   ],
   "id": "f3426b9aa9e81b0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 1.1863905325443787\n",
      "Median: 1.0\n",
      "Number of cases with only one extra line: 0.8431952662721893\n",
      "Max number of extra line: 4\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7be038769661dec1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T18:41:24.947718Z",
     "start_time": "2024-03-27T18:41:24.934065Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       228\n",
      "           1       0.78      0.92      0.84       236\n",
      "           2       0.89      0.91      0.90       200\n",
      "           3       0.90      0.88      0.89       112\n",
      "           4       0.78      0.90      0.84        20\n",
      "           5       0.25      1.00      0.40         1\n",
      "           6        nan       nan       nan         0\n",
      "           7        nan       nan       nan         0\n",
      "           8        nan       nan       nan         0\n",
      "           9        nan       nan       nan         0\n",
      "          10        nan       nan       nan         0\n",
      "          11        nan       nan       nan         0\n",
      "          12        nan       nan       nan         0\n",
      "          13        nan       nan       nan         0\n",
      "          14        nan       nan       nan         0\n",
      "          15        nan       nan       nan         0\n",
      "          16        nan       nan       nan         0\n",
      "          17        nan       nan       nan         0\n",
      "          18        nan       nan       nan         0\n",
      "          19        nan       nan       nan         0\n",
      "          20        nan       nan       nan         0\n",
      "          21        nan       nan       nan         0\n",
      "          22        nan       nan       nan         0\n",
      "          23        nan       nan       nan         0\n",
      "          24        nan       nan       nan         0\n",
      "          25        nan       nan       nan         0\n",
      "          26        nan       nan       nan         0\n",
      "          27        nan       nan       nan         0\n",
      "          28        nan       nan       nan         0\n",
      "          29        nan       nan       nan         0\n",
      "          30        nan       nan       nan         0\n",
      "          31        nan       nan       nan         0\n",
      "          32        nan       nan       nan         0\n",
      "          33        nan       nan       nan         0\n",
      "          34        nan       nan       nan         0\n",
      "          35        nan       nan       nan         0\n",
      "          36        nan       nan       nan         0\n",
      "          37        nan       nan       nan         0\n",
      "          38        nan       nan       nan         0\n",
      "          39        nan       nan       nan         0\n",
      "          40        nan       nan       nan         0\n",
      "          41        nan       nan       nan         0\n",
      "          42        nan       nan       nan         0\n",
      "          43        nan       nan       nan         0\n",
      "          44        nan       nan       nan         0\n",
      "          45        nan       nan       nan         0\n",
      "          46        nan       nan       nan         0\n",
      "          47        nan       nan       nan         0\n",
      "          48        nan       nan       nan         0\n",
      "          49        nan       nan       nan         0\n",
      "          50        nan       nan       nan         0\n",
      "          51        nan       nan       nan         0\n",
      "          52        nan       nan       nan         0\n",
      "          53        nan       nan       nan         0\n",
      "          54        nan       nan       nan         0\n",
      "          55        nan       nan       nan         0\n",
      "          56        nan       nan       nan         0\n",
      "          57        nan       nan       nan         0\n",
      "          58        nan       nan       nan         0\n",
      "          59        nan       nan       nan         0\n",
      "          60        nan       nan       nan         0\n",
      "          61        nan       nan       nan         0\n",
      "          62        nan       nan       nan         0\n",
      "          63        nan       nan       nan         0\n",
      "          64        nan       nan       nan         0\n",
      "          65        nan       nan       nan         0\n",
      "          66        nan       nan       nan         0\n",
      "          67        nan       nan       nan         0\n",
      "          68        nan       nan       nan         0\n",
      "          69        nan       nan       nan         0\n",
      "          70        nan       nan       nan         0\n",
      "          71        nan       nan       nan         0\n",
      "          72        nan       nan       nan         0\n",
      "          73        nan       nan       nan         0\n",
      "          74        nan       nan       nan         0\n",
      "          75        nan       nan       nan         0\n",
      "          76        nan       nan       nan         0\n",
      "          77        nan       nan       nan         0\n",
      "          78        nan       nan       nan         0\n",
      "          79        nan       nan       nan         0\n",
      "          80        nan       nan       nan         0\n",
      "          81        nan       nan       nan         0\n",
      "          82        nan       nan       nan         0\n",
      "          83        nan       nan       nan         0\n",
      "          84        nan       nan       nan         0\n",
      "          85        nan       nan       nan         0\n",
      "          86        nan       nan       nan         0\n",
      "          87        nan       nan       nan         0\n",
      "          88        nan       nan       nan         0\n",
      "          89        nan       nan       nan         0\n",
      "          90        nan       nan       nan         0\n",
      "          91        nan       nan       nan         0\n",
      "          92        nan       nan       nan         0\n",
      "          93        nan       nan       nan         0\n",
      "          94        nan       nan       nan         0\n",
      "          95        nan       nan       nan         0\n",
      "          96        nan       nan       nan         0\n",
      "          97        nan       nan       nan         0\n",
      "          98        nan       nan       nan         0\n",
      "          99        nan       nan       nan         0\n",
      "\n",
      "   micro avg       0.83      0.91      0.87       797\n",
      "   macro avg       0.74      0.92      0.79       797\n",
      "weighted avg       0.84      0.91      0.87       797\n",
      " samples avg       0.88      0.93      0.86       797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix, accuracy_score, jaccard_score, hamming_loss\n",
    "\n",
    "print(classification_report(truth, predictions, zero_division=np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ceaf199-3988-4e7b-af26-0246a4ddf4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7026086956521739"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(truth, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07c28798-1600-4cea-bd8b-3e638c1daa8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8269565217391305"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_score(truth, predictions, average=\"samples\", zero_division=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f6f3f88-c5b8-4f54-a9eb-a949f3a2f143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo/miniconda3/envs/formhe/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7939130434782609"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_score(truth, predictions, average=\"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc966c5e-294c-48da-9217-cf2260f3f562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7707006369426752"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_score(truth, predictions, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ed0c95c-1036-42ad-b673-13af2e597bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003756521739130435"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_loss(truth, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
